{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "716f9b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "from dataset import DSpritesDataModule\n",
    "from models.vae import VAE\n",
    "from models.factor_vae import FactorVAE\n",
    "from utils import visualize_reconstructions, save_individual_latent_traversal_grids, get_accelerator\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b830ccbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configurazione caricata per il model_type: factor_vae\n",
      "  model_type: factor_vae\n",
      "  latent_dim: 10\n",
      "  epochs: 1\n",
      "  batch_size: 16\n",
      "  num_workers: 2\n",
      "  seed: 1234\n",
      "  patience_early_stopping: 5\n",
      "  accelerator: mps\n",
      "  output_dir: generated_images_final_nb\n",
      "  n_reconstruction_images: 8\n",
      "  n_images_for_traversal_grids: 3\n",
      "  n_traversal_steps_per_dim: 7\n",
      "  traversal_range_min: -2.5\n",
      "  traversal_range_max: 2.5\n",
      "  lr_vae: 0.0001\n",
      "  lr_disc: 0.0001\n",
      "  gamma: 35.0\n",
      "  disc_hidden_units: 1000\n",
      "  disc_layers: 6\n"
     ]
    }
   ],
   "source": [
    "class Args:\n",
    "    pass\n",
    "\n",
    "args = Args()\n",
    "\n",
    "# --- IMPOSTAZIONI MODELLO E TRAINING ---\n",
    "args.model_type = 'factor_vae'\n",
    "\n",
    "args.latent_dim = 10\n",
    "args.epochs = 1\n",
    "args.batch_size = 16\n",
    "args.num_workers = 2\n",
    "args.seed = 1234\n",
    "args.patience_early_stopping = 5\n",
    "args.accelerator = get_accelerator()\n",
    "\n",
    "# --- IMPOSTAZIONI OUTPUT E VISUALIZZAZIONE ---\n",
    "args.output_dir = \"generated_images_final_nb\"\n",
    "args.n_reconstruction_images = 8\n",
    "args.n_images_for_traversal_grids = 3\n",
    "args.n_traversal_steps_per_dim = 7\n",
    "args.traversal_range_min = -2.5\n",
    "args.traversal_range_max = 2.5\n",
    "\n",
    "# --- IPERPARAMETRI SPECIFICI PER VAE ---\n",
    "if args.model_type == 'vae':\n",
    "    args.lr = 1e-4\n",
    "    args.beta = 4.0\n",
    "\n",
    "# --- IPERPARAMETRI SPECIFICI PER FactorVAE ---\n",
    "elif args.model_type == 'factor_vae':\n",
    "    args.lr_vae = 1e-4\n",
    "    args.lr_disc = 1e-4  # Come da paper [cite: 255]\n",
    "    args.gamma = 35.0    # Valore da paper per dSprites [cite: 146]\n",
    "    args.disc_hidden_units = 1000 # Come da paper [cite: 258]\n",
    "    args.disc_layers = 6          # Come da paper [cite: 258]\n",
    "\n",
    "print(f\"Configurazione caricata per il model_type: {args.model_type}\")\n",
    "for k, v in vars(args).items():\n",
    "    print(f\"  {k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83c80bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 1234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed impostato a: 1234\n",
      "Utilizzo del device: mps (Accelerator: mps)\n"
     ]
    }
   ],
   "source": [
    "pl.seed_everything(args.seed)\n",
    "device = torch.device(args.accelerator if args.accelerator != \"cpu\" else \"cpu\")\n",
    "print(f\"Seed impostato a: {args.seed}\")\n",
    "print(f\"Utilizzo del device: {device} (Accelerator: {args.accelerator})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d03701a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = DSpritesDataModule(\n",
    "    batch_size=args.batch_size,\n",
    "    num_workers=args.num_workers,\n",
    "    data_dir=\"data/dsprites\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c968c213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modello FactorVAE con gamma=35.0 inizializzato.\n",
      "Struttura del modello:\n",
      "FactorVAE(\n",
      "  (encoder): Encoder(\n",
      "    (conv1): Conv2d(1, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (conv2): Conv2d(32, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (conv3): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (conv4): Conv2d(64, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (fc_intermediate): Linear(in_features=1024, out_features=128, bias=True)\n",
      "    (fc_mean): Linear(in_features=128, out_features=10, bias=True)\n",
      "    (fc_logvar): Linear(in_features=128, out_features=10, bias=True)\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (fc1): Linear(in_features=10, out_features=128, bias=True)\n",
      "    (fc2): Linear(in_features=128, out_features=1024, bias=True)\n",
      "    (upconv1): ConvTranspose2d(64, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (upconv2): ConvTranspose2d(64, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (upconv3): ConvTranspose2d(32, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (upconv4): ConvTranspose2d(32, 1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  )\n",
      "  (discriminator): Discriminator(\n",
      "    (model): Sequential(\n",
      "      (0): Linear(in_features=10, out_features=1000, bias=True)\n",
      "      (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "      (2): Linear(in_features=1000, out_features=1000, bias=True)\n",
      "      (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "      (4): Linear(in_features=1000, out_features=1000, bias=True)\n",
      "      (5): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "      (6): Linear(in_features=1000, out_features=1000, bias=True)\n",
      "      (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "      (8): Linear(in_features=1000, out_features=1000, bias=True)\n",
      "      (9): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "      (10): Linear(in_features=1000, out_features=1000, bias=True)\n",
      "      (11): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "      (12): Linear(in_features=1000, out_features=1, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = None\n",
    "monitor_metric = None # Metrica da monitorare per checkpoint e early stopping\n",
    "\n",
    "if args.model_type == 'vae':\n",
    "    model = VAE(latent_dim=args.latent_dim, lr=args.lr, beta=args.beta)\n",
    "    monitor_metric = 'val_loss'\n",
    "    print(f\"Modello VAE con beta={args.beta} inizializzato.\")\n",
    "elif args.model_type == 'factor_vae':\n",
    "    model = FactorVAE(\n",
    "        latent_dim=args.latent_dim,\n",
    "        lr_vae=args.lr_vae,\n",
    "        lr_disc=args.lr_disc,\n",
    "        gamma=args.gamma,\n",
    "        disc_hidden_units=args.disc_hidden_units,\n",
    "        disc_layers=args.disc_layers\n",
    "    )\n",
    "    monitor_metric = 'val_vae_loss'\n",
    "    print(f\"Modello FactorVAE con gamma={args.gamma} inizializzato.\")\n",
    "else:\n",
    "    raise ValueError(\"Invalid model_type specified in args.\")\n",
    "\n",
    "if model:\n",
    "    print(f\"Struttura del modello:\\n{model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a430e69a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Callbacks e Logger configurati.\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(args.output_dir):\n",
    "    os.makedirs(args.output_dir, exist_ok=True)\n",
    "\n",
    "# Callback per salvare il miglior modello\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=os.path.join(\"checkpoints\", args.model_type), # Salva in checkpoints/model_type/\n",
    "    filename=f\"{{epoch}}-{{{monitor_metric}:.2f}}\",\n",
    "    save_top_k=1,\n",
    "    verbose=True,\n",
    "    monitor=monitor_metric,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "# Callback per early stopping\n",
    "early_stop_callback = EarlyStopping(\n",
    "    monitor=monitor_metric,\n",
    "    patience=args.patience_early_stopping,\n",
    "    verbose=True,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "# Logger per TensorBoard\n",
    "tensorboard_logger = TensorBoardLogger(\n",
    "    save_dir=\"logs/\", # Salva in logs/\n",
    "    name=args.model_type\n",
    ")\n",
    "\n",
    "print(\"Callbacks e Logger configurati.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b662dea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainer inizializzato.\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(\n",
    "    max_epochs=args.epochs,\n",
    "    accelerator=args.accelerator,\n",
    "    devices=1 if args.accelerator != \"cpu\" else None,\n",
    "    callbacks=[checkpoint_callback, early_stop_callback],\n",
    "    logger=tensorboard_logger,\n",
    "    enable_progress_bar=True\n",
    ")\n",
    "print(\"Trainer inizializzato.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2268ff0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Inizio addestramento per {args.model_type}...\")\n",
    "trainer.fit(model, datamodule=dm)\n",
    "print(\"Addestramento completato.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f20a9b75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup del datamodule per lo stage 'test'...\n",
      "Dataset split: Train=516095, Val=110592, Test=110593\n",
      "Test dataloader pronto con 110593 campioni.\n"
     ]
    }
   ],
   "source": [
    "if dm.dsprites_test is None:\n",
    "    print(\"Setup del datamodule per lo stage 'test'...\")\n",
    "    dm.setup(stage='test')\n",
    "\n",
    "test_dataloader = dm.test_dataloader()\n",
    "\n",
    "if not test_dataloader or len(test_dataloader.dataset) == 0:\n",
    "    print(\"ATTENZIONE: Test dataloader non disponibile o vuoto.\")\n",
    "else:\n",
    "    print(f\"Test dataloader pronto con {len(test_dataloader.dataset)} campioni.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "544d2a6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caricamento del miglior modello da: ./checkpoints/factor_vae/fvae.ckpt\n",
      "Modello caricato e impostato in modalità evaluazione.\n"
     ]
    }
   ],
   "source": [
    "best_model_path = \"./checkpoints/factor_vae/fvae.ckpt\"\n",
    "trained_model_for_viz = None\n",
    "\n",
    "if not best_model_path or not os.path.exists(best_model_path):\n",
    "    print(f\"Nessun modello '{args.model_type}' trovato in {best_model_path} o il percorso non esiste.\")\n",
    "    print(\"Sto usando il modello corrente in memoria (potrebbe non essere il migliore).\")\n",
    "    trained_model_for_viz = model # Usa il modello corrente in memoria\n",
    "else:\n",
    "    print(f\"Caricamento del miglior modello da: {best_model_path}\")\n",
    "    if args.model_type == 'vae':\n",
    "        trained_model_for_viz = VAE.load_from_checkpoint(best_model_path)\n",
    "    elif args.model_type == 'factor_vae':\n",
    "        # Nota: Se gli iperparametri passati a FactorVAE(...) non sono salvati con save_hyperparameters()\n",
    "        # potresti doverli passare di nuovo qui. Ma Lightning solitamente li gestisce.\n",
    "        trained_model_for_viz = FactorVAE.load_from_checkpoint(best_model_path)\n",
    "\n",
    "if trained_model_for_viz:\n",
    "    trained_model_for_viz.to(device)\n",
    "    trained_model_for_viz.eval()\n",
    "    print(\"Modello caricato e impostato in modalità evaluazione.\")\n",
    "else:\n",
    "    print(\"Errore: Nessun modello disponibile per la visualizzazione.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "893a306a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Visualizzazione e salvataggio delle ricostruzioni per factor_vae...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/carlodenardin/miniconda3/envs/vae-compare/lib/python3.11/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Immagine delle ricostruzioni salvata in: generated_images_final_nb/factor_vae/simple_reconstructions/reconstructions_ep0.png\n",
      "Immagini di ricostruzione salvate in: generated_images_final_nb/factor_vae/simple_reconstructions\n",
      "\n",
      "Generazione e salvataggio delle griglie di attraversamento latente per factor_vae...\n",
      "Griglia di traversata per immagine 1 salvata in: generated_images_final_nb/factor_vae/individual_traversal_grids/traversal_grid_ep0_img_1.png\n",
      "Griglia di traversata per immagine 2 salvata in: generated_images_final_nb/factor_vae/individual_traversal_grids/traversal_grid_ep0_img_2.png\n",
      "Griglia di traversata per immagine 3 salvata in: generated_images_final_nb/factor_vae/individual_traversal_grids/traversal_grid_ep0_img_3.png\n",
      "Griglie di attraversamento salvate in: generated_images_final_nb/factor_vae/individual_traversal_grids\n"
     ]
    }
   ],
   "source": [
    "if trained_model_for_viz and test_dataloader and len(test_dataloader.dataset) > 0:\n",
    "    print(f\"\\nVisualizzazione e salvataggio delle ricostruzioni per {args.model_type}...\")\n",
    "    \n",
    "    reconstruction_output_dir = os.path.join(args.output_dir, args.model_type, \"simple_reconstructions\")\n",
    "    if not os.path.exists(reconstruction_output_dir):\n",
    "        os.makedirs(reconstruction_output_dir, exist_ok=True)\n",
    "        \n",
    "    visualize_reconstructions(\n",
    "        trained_model_for_viz,\n",
    "        test_dataloader,\n",
    "        n_images=args.n_reconstruction_images,\n",
    "        device=device,\n",
    "        output_dir=reconstruction_output_dir,\n",
    "        output_filename=f\"reconstructions_ep{trained_model_for_viz.current_epoch if hasattr(trained_model_for_viz, 'current_epoch') else 'N_A'}.png\"\n",
    "    )\n",
    "    print(f\"Immagini di ricostruzione salvate in: {reconstruction_output_dir}\")\n",
    "else:\n",
    "    print(\"Saltata visualizzazione delle ricostruzioni (modello o test_dataloader non pronti).\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ### 10.3 Visualizzazione degli Attraversamenti Latenti (Latent Traversals)\n",
    "# \n",
    "# Generiamo griglie di attraversamento per alcune immagini del test set. Ogni griglia mostra come l'immagine generata cambia quando si attraversa una singola dimensione latente, mantenendo le altre fisse. Questo aiuta a valutare qualitativamente il disentanglement.\n",
    "\n",
    "# %%\n",
    "if trained_model_for_viz and test_dataloader and len(test_dataloader.dataset) > 0:\n",
    "    print(f\"\\nGenerazione e salvataggio delle griglie di attraversamento latente per {args.model_type}...\")\n",
    "    \n",
    "    traversal_output_dir = os.path.join(args.output_dir, args.model_type, \"individual_traversal_grids\")\n",
    "    if not os.path.exists(traversal_output_dir):\n",
    "        os.makedirs(traversal_output_dir, exist_ok=True)\n",
    "        \n",
    "    save_individual_latent_traversal_grids(\n",
    "        trained_model_for_viz,\n",
    "        test_dataloader,\n",
    "        n_images_to_show=args.n_images_for_traversal_grids,\n",
    "        n_traversal_steps=args.n_traversal_steps_per_dim,\n",
    "        traverse_range=(args.traversal_range_min, args.traversal_range_max),\n",
    "        device=device,\n",
    "        output_dir=traversal_output_dir,\n",
    "        filename_prefix=f\"traversal_grid_ep{trained_model_for_viz.current_epoch if hasattr(trained_model_for_viz, 'current_epoch') else 'N_A'}_img_\"\n",
    "    )\n",
    "    print(f\"Griglie di attraversamento salvate in: {traversal_output_dir}\")\n",
    "else:\n",
    "    print(\"Saltata generazione delle griglie di attraversamento (modello o test_dataloader non pronti).\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vae-compare",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
